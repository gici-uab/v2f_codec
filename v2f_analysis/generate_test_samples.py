#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""This script:

  - Produces .v2fc files from available .v2fh files in ./prebuilt_forests

  - Generates test samples, usable for instance from the unitests

  - Generates fuzzing samples for exhaustive prototype testing

There is no need to invoke this script manually,
as it is automatically invoked by make.
"""
__author__ = "Miguel Hern√°ndez Cabronero <miguel.hernandez@uab.cat>"
__date__ = "03/08/2020"

import os
import sys
import glob
import shutil
import re
import subprocess
import bitstream
import random
import enb
from enb.config import options

import cli_fuzzer_seeder

random.seed(0x1f414f31 * 0xbadc0ff33 % 0xffffffff)

remove_preexisting = True

# C prototype project root
project_root = os.path.dirname(enb.config.options.project_root)
enb.config.options.project_root = project_root

from fuzzing_queues_to_cmin import queue_to_fuzzer_cmin
from fuzzing_queues_to_cmin import clean_fuzzer_queues

# Directory where the test_samples.h and test_samples.c files are to be output
test_src_dir = os.path.join(project_root, "test")
assert os.path.isdir(test_src_dir), test_src_dir
test_samples_h_path = os.path.join(test_src_dir, "test_samples.h")
test_samples_c_path = os.path.join(test_src_dir, "test_samples.c")

# Directory with input HK/TM samples,
# containing unsigned raw images of different sizes and bitdepths.
unittest_samples_dir = os.path.join(
    project_root, "testdata", "unittest_samples")
os.makedirs(unittest_samples_dir, exist_ok=True)
assert os.path.isdir(unittest_samples_dir)

# Prebuilt forests (.v2fh) are produced elsewhere and copied, these contain .v2fc files
prebuilt_codec_dir = os.path.join(
    project_root, "testdata", "prebuilt_codecs")
os.makedirs(prebuilt_codec_dir, exist_ok=True)
assert os.path.isdir(prebuilt_codec_dir)

# Directory with samples for the regular fuzzers
## Entropy coder fuzzer
output_fuzzing_samples_entropy_coder_dir = os.path.join(
    project_root, "testdata", "fuzzing_samples", "seed",
    "fuzzer_entropy_coder")
os.makedirs(output_fuzzing_samples_entropy_coder_dir, exist_ok=True)
assert os.path.isdir(output_fuzzing_samples_entropy_coder_dir)

## Entropy decoder fuzzer
output_fuzzing_samples_entropy_decoder_dir = os.path.join(
    project_root, "testdata", "fuzzing_samples", "seed",
    "fuzzer_entropy_decoder")
os.makedirs(output_fuzzing_samples_entropy_decoder_dir, exist_ok=True)

## Compress->decompress fuzzer
output_fuzzing_samples_compress_decompress = os.path.join(
    project_root, "testdata", "fuzzing_samples", "seed",
    "fuzzer_compress_decompress")
os.makedirs(output_fuzzing_samples_compress_decompress, exist_ok=True)

# Directory with fuzzing samples for the command_line fuzzer
#   - 0 : verify_codec
#   - 1 : v2f_compress

CLI_VERIFY_CODEC = 0
CLI_V2F_COMPRESS = 1

output_fuzzing_cli_paths = [
    os.path.join(project_root, "testdata", "fuzzing_samples", "seed",
                 "command_line_fuzzer", str(i)) for i in range(2)]
for p in output_fuzzing_cli_paths:
    shutil.rmtree(p, ignore_errors=True)
    os.makedirs(p)
    assert os.path.isdir(p)

# 0 - Directory with prebuilt vectors containing the V2F codecs to be verified
output_prebuilt_verify_codec_dir = output_fuzzing_cli_paths[CLI_VERIFY_CODEC]

# 1 - Directory with fuzzing vectors for the compressor
output_prebuilt_v2f_codec_dir = output_fuzzing_cli_paths[CLI_V2F_COMPRESS]

verification_bin_path = os.path.join(project_root, "build", "bin",
                                     "v2f_verify_codec")
assert os.path.isfile(verification_bin_path), \
    f"verification_bin_path={repr(verification_bin_path)} does not exist. " \
    f"Please Run `make` first."

# When True, afl-cmin is applied to the cross-validation input and output
minimize_crossvalidation_data = False


class HKTMSequenceInfo:
    """Represent all needed information about a sequence of HK/TM packets.
    """
    max_description_length = 1024

    def __init__(self, original_path, bytes, description=""):
        assert os.path.isfile(original_path), original_path
        assert len(description) <= self.max_description_length
        self.original_path = original_path
        self.description = description
        self.bytes = bytes

    def __repr__(self):
        return f"HKTMSequenceInfo({', '.join(str(k) + '=' + repr(v) for k, v in self.__dict__.items())})"


def sequence_info_to_output_name(sequence_info, sequence_index):
    return f"sequence{sequence_index:06d}_{sequence_info.bytes:06d}bytes.raw"


# Template for test_samples.h - parameter: sequence_list_length
template_samples_h = """
/**
 * @file
 *
 * Tools to automate the testing of test samples.
 *
 * (automatically generated by metasrc/generate_test_samples.py)
 *
 */
 
#ifndef TEST_SAMPLES_H
#define TEST_SAMPLES_H

#include <stdint.h>

/** 
 * @struct v2f_test_sample_t
 * 
 * Represent all needed information about a test sequence.
 */
typedef struct {{
    /// Path to the file with data
    char const *const path;
    /// Optional information about the sample
    char const *const description;
    /// Number of bytes available in the file
    uint32_t const bytes;
}} v2f_test_sample_t;

/// Test sample constants
enum {{
    /// Number of samples available for testing.
	V2F_C_TEST_SAMPLE_COUNT = {sequence_list_length}
}};

/// List of all v2f_test_sample_t instances. 
extern v2f_test_sample_t all_test_samples[V2F_C_TEST_SAMPLE_COUNT];

#endif /* TEST_SAMPLES_H */
"""

# Template for test_samples.c
# parameter: test_sample_repr_list (list of test_sample_t initializations)
template_samples_c = """
/**
 * @file
 *
 * Definition of the list of all available test samples.
 *
 * @see test_samples.h for further information.
 *
 */

#include "test_samples.h"

v2f_test_sample_t all_test_samples[V2F_C_TEST_SAMPLE_COUNT] = {{
{test_sample_repr_list}
}};
"""


def generate_unittest_samples():
    """Generate a set of samples of different lenghts
    """
    component_count = 1
    for bytes_per_sample in [1, 2]:
        for width in [8, 256, 257, 1024]:
            height = width
            tag = "u8be" if bytes_per_sample == 1 else "u16be"
            with open(os.path.join(unittest_samples_dir,
                                   f"example_sample_{tag}-1x{height}x{width}.raw"),
                      "wb") as output_file:
                output_file.write(
                    bytes([0x00, 0x00, 0xff, 0xff, 0xff, 0x00, 0x00, 0xff]))
                output_file.write(bytes(list(
                    (x ** 2 * width + x ** 3 * height // 2) % 255
                    for x in range(
                        component_count * width * height * bytes_per_sample
                        - 8))))


def get_full_sequence_info_list():
    """Get a list of all existing original and synthetic instances
    corresponding to existing samples.
    """
    return get_example_info_list() + get_synthetic_sequence_info_list()


def get_example_info_list():
    """Get the list of all existing samples in the example dir.
    """
    sample_path_list = glob.glob(
        os.path.join(unittest_samples_dir, "*"),
        recursive=True)

    return [HKTMSequenceInfo(
        original_path=p.replace(os.path.abspath(unittest_samples_dir),
                                os.path.abspath(
                                    os.path.join(project_root, "testdata",
                                                 "unittest_samples")).replace(
                                    os.sep + os.sep, os.sep)),
        description=f"Test from {os.path.basename(p)}",
        bytes=os.path.getsize(p))
        for p in sample_path_list]


def get_synthetic_sequence_info_list():
    """Generate synthetic sequences and return a list of HKTMSequenceInfo instances,
    one per sequence.
    """
    return []


def generate_fuzzing_entropy_decoder_samples(
        output_dir=output_fuzzing_samples_entropy_decoder_dir):
    """Generate samples for fuzzing that include parameter configuration
    for each packet (header format is described at the top of the script).
    """
    generate_files_with_header(output_dir=output_dir)
    # queues is designed to contain all seeds and fuzzed data
    copy_seed_to_queues(seed_dir=output_dir)


def generate_fuzzing_entropy_coder_samples(
        output_dir=output_fuzzing_samples_entropy_coder_dir):
    """Generate samples for the entropy coder
    """
    generate_files_with_header(output_dir=output_dir)
    # queues is designed to contain all seeds and fuzzed data
    copy_seed_to_queues(seed_dir=output_dir)


def generate_fuzzing_compress_decompress(
        output_dir=output_fuzzing_samples_compress_decompress):
    """Generate some seed samples for the compress->decompres fuzzer.
    """
    # All 256-symbol codec definitions are put up for testing
    available_codecs = sorted(list(glob.glob(os.path.join(
        prebuilt_codec_dir, "**", "*256symbols*.v2fc"), recursive=True)))

    # Only a few samples are selected, since those are to be fuzzed including size
    available_samples = glob.glob(os.path.join(
        unittest_samples_dir, "**", "*.raw"), recursive=True)
    selected_sample_paths = [p for p in available_samples if
                            os.path.getsize(p) < 512*512][:5]

    if options.verbose > 1:
        print(f"Generating {len(selected_sample_paths) * len(available_codecs)} "
              f"fuzzer_compress_decompress vectors...")

    for sample_path in selected_sample_paths:
        sample_size = os.path.getsize(sample_path)
        for codec_path in available_codecs:
            output_path = os.path.join(
                output_fuzzing_samples_compress_decompress,
                f"fuzzer_compress_decompress_sample"
                f"_{os.path.basename(sample_path)}"
                f"_{os.path.basename(codec_path)}.fuzz")
            with open(output_path, "wb") as output_file:
                # 1 - Write sample size, 4 bytes, big endian
                output_file.write(bytes([
                    (sample_size >> 24) & 0xff,
                    (sample_size >> 16) & 0xff,
                    (sample_size >> 8) & 0xff,
                    sample_size & 0xff]))

                # 2 - Write codec file path length, 2 bytes, big endian
                codec_path_length = len(os.path.abspath(codec_path))
                output_file.write(bytes([
                    (codec_path_length >> 8) & 0xff,
                    codec_path_length & 0xff]))

                # 3 - Write codec file path
                output_file.write(bytes(
                    os.path.abspath(codec_path), encoding="ascii"))

                # 4 - Write sample contents
                with open(sample_path, "rb") as sample_file:
                    output_file.write(sample_file.read())
            if options.verbose > 1:
                print(f"... generated {output_path}.")

    # queues is designed to contain all seeds and fuzzed data
    copy_seed_to_queues(seed_dir=output_dir)


def generate_files_with_header(output_dir):
    """Generate a set of test vectors with a header:_
    - sample count (32 bits, big endian, unsigned)
    - bytes per sample (8 bits)
    """
    sequence_index = 0
    for sample_count in [1, 2, 255, 256, 2048]:
        for bytes_per_index in [1, 2]:
            module = (2 ** (8 * bytes_per_index))
            output_path = os.path.join(output_dir,
                                       f"sample_{sequence_index:06d}.raw")
            with bitstream.OutputBitStream(output_path) as obs:
                obs.put_unsigned_value(sample_count, 8 * 4)
                obs.put_unsigned_value(bytes_per_index, 8 * 1)
                for i in range(sample_count):
                    obs.put_unsigned_value(i % module, 8 * bytes_per_index)
            sequence_index += 1


def copy_seed_to_queues(seed_dir, queues_dir=None):
    seed_dir = os.path.abspath(seed_dir)
    queues_dir = seed_dir.replace('seed', 'queues') \
        if queues_dir is None else queues_dir
    for input_path in [p for p in glob.glob(
            os.path.join(seed_dir, "**", "*"), recursive=True)
                       if os.path.isfile(p)]:
        output_path = os.path.join(queues_dir, os.path.basename(input_path))
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        shutil.copy(input_path, output_path)


def generate_command_line_fuzzer_samples():
    """Generate sample for the cli fuzzers.
    """
    print("Generating command line fuzzer samples...")

    for p in output_fuzzing_cli_paths:
        os.makedirs(p, exist_ok=True)

    command_line_fuzzer_basedir = os.path.join(
        project_root, "testdata", "fuzzing_samples", "seed",
        "command_line_fuzzer")

    # Copy seed to queues
    print("\tCopying seeds to queues...")
    for i in range(2):
        output_dir = os.path.join(command_line_fuzzer_basedir, str(i))
        # queues is designed to contain all seeds and fuzzed data
        # for maximum test coverage
        if not os.path.isdir(output_dir):
            print(f"[W]arning: command line seed {i} missing; "
                  f"{output_dir} not found. "
                  f"Try running {os.path.basename(__file__)} directly instead "
                  f"if you have not already.")
            continue
        copy_seed_to_queues(seed_dir=output_dir)


def generate_c_sources():
    """Copy the original MHDC HK/TM test set, renaming it in a consistent manner.
    Then generate all synthetic samples.
    Finally, for each original and syntetic sample, generate one valid config file
    (containing valid compression parameters for each packet).
    """
    print("Generating samples and configs...")

    full_sequence_info_list = get_full_sequence_info_list()

    # Generate test_samples.h
    with open(test_samples_h_path, "w") as test_samples_h_file:
        test_samples_h_file.write(template_samples_h.strip().format(
            sequence_list_length=len(full_sequence_info_list)))
        test_samples_h_file.write("\n")

    # Generate test_samples.c
    def sequence_info_to_c_initialization(sequence_info, sequence_index):
        """Obtain a C initialization string for the given sequence info
        """
        path = os.path.abspath(sequence_info.original_path).replace(
            os.path.abspath(project_root), ".")

        string_elements = ["    {\n"]
        string_elements.append(f"        .path = \"{path}\",\n")
        string_elements.append(
            f"        .description = \"{sequence_info.description}\",\n")
        string_elements.append(f"        .bytes = {sequence_info.bytes},\n")
        string_elements.append("    },")
        return "".join(string_elements)

    test_sample_repr_list = "\n".join(
        sequence_info_to_c_initialization(sequence_index=i, sequence_info=si)
        for i, si in enumerate(full_sequence_info_list))
    with open(test_samples_c_path, "w") as test_samples_c_file:
        contents = template_samples_c.strip().format(
            test_sample_repr_list=test_sample_repr_list)
        test_samples_c_file.write(contents)
        test_samples_c_file.write("\n")


def v2fh_to_v2fc(v2fh_path, v2fc_path, verification_bin_path=None,
                 quantization_mode=0, step_size=1, decorrelator_mode=0):
    """Transform a v2fh forest definition file into a v2fc codec definition file.

    The produced codec file consists of:
        - quantization mode
        - quantization step size configuration
        - decorrelation mode configuration
        - the contents of v2fh_path

    If verification_bin_path is not None and step_size is 1,
    it is a path to a binary that is used to validate the
    produced v2fc file.

    The defaults used by this function result in an entropy coding only
    pipeline.
    """
    assert v2fh_path, v2fh_path
    assert v2fc_path, v2fc_path

    os.makedirs(os.path.dirname(os.path.abspath(v2fc_path)), exist_ok=True)
    with open(v2fh_path, "rb") as v2fh_file, \
            open(v2fc_path, "wb") as v2fc_file:
        if options.verbose > 1:
            print(f"[C]onverting v2fh_path={v2fh_path} into {v2fc_path}")

        # Quantization mode
        assert 0 <= quantization_mode <= 255
        v2fc_file.write(bytes([quantization_mode]))

        # step size
        assert 1 <= step_size <= 255
        v2fc_file.write(bytes([((step_size >> 24) & 0xff),
                               ((step_size >> 16) & 0xff),
                               ((step_size >> 8) & 0xff),
                               step_size & 0xff]))
        v2fc_file.flush()
        assert os.path.getsize(v2fc_path) == 5
        # decorrelator mode
        assert 0 <= decorrelator_mode <= 2
        v2fc_file.write(bytes(
            [((decorrelator_mode >> 8) & 0xff), decorrelator_mode & 0xff]))
        v2fc_file.flush()
        assert os.path.getsize(v2fc_path) == 7
        # max sample value
        try:
            symbol_count = int(re.search(
                r"_(\d+)symbols_", os.path.basename(v2fh_path)).group(1))
        except AttributeError:
            symbol_count = int(re.search(
                r"_symbolcount-(\d+)_", os.path.basename(v2fh_path)).group(1))

        max_sample_value = symbol_count - 1

        assert 1 <= max_sample_value <= 65536, max_sample_value
        msv_bytes = bytes([
            (max_sample_value >> 24) & 0xff,
            (max_sample_value >> 16) & 0xff,
            (max_sample_value >> 8) & 0xff,
            max_sample_value & 0xff])
        v2fc_file.write(msv_bytes)
        v2fc_file.flush()
        assert os.path.getsize(v2fc_path) == 11

        # forest id: 0 means data is included instead of referenced
        v2fc_file.write(bytes([0] * 4))
        v2fc_file.flush()
        assert os.path.getsize(v2fc_path) == 15
        # V2F forest definition
        v2fc_file.write(v2fh_file.read())
        v2fc_file.flush()

    if verification_bin_path is not None and (
            step_size == 1 or quantization_mode == 0):
        invocation = f"{verification_bin_path} {v2fc_path}"
        status, output = subprocess.getstatusoutput(invocation)
        if status != 0 or (
                ("Successfully loaded V2F codec" not in output)
                and len(output) > 0):
            raise Exception(
                f"[E]rror verifying {v2fc_path}. " +
                "Status = {} != 0.\nInput=[{}].\nOutput=[{}]".format(
                    status, invocation, output))
        if options.verbose:
            print(f"\t... verification of {v2fc_path} ok!")


def v2fc_to_cli_v2fc(v2fc_path, cli_v2fc_path):
    """Transform a v2fc codec definition file into a CLI test vector
    for that codec.
    """
    os.makedirs(os.path.dirname(os.path.abspath(cli_v2fc_path)), exist_ok=True)

    with cli_fuzzer_seeder.CLICommandFileCreator(
            CLI_VERIFY_CODEC, cli_v2fc_path) as cli_creator:
        cli_creator.add_command(cli_fuzzer_seeder.InputFile(v2fc_path))

    if os.path.getsize(cli_v2fc_path) >= 1024 ** 2:
        if options.verbose:
            print(
                f"[S]kipping sample too big: {cli_v2fc_path} "
                f"(they grow in CLI vector form!)")
        os.remove(cli_v2fc_path)


def import_v2f_codecs():
    """Generate .v2fc codec definition files
    from existing .v2fh forest definition files.

    Lossless compression is added to the seed tests only, but the fuzzer
    shall automatically generate lossless cases too.
    """
    # Input folder with the v2fh files
    input_v2fh_dir = os.path.abspath(os.path.join(project_root, "metasrc", "prebuilt_forests"))

    # Output dirs are cleared before generating the v2fc and cli_v2fc files
    output_v2fc_dir = os.path.abspath(
        os.path.join(project_root, "testdata", "prebuilt_codecs"))
    output_cli_v2fc_dir = os.path.abspath(
        output_fuzzing_cli_paths[CLI_VERIFY_CODEC])
    for p in [output_v2fc_dir, output_cli_v2fc_dir]:
        shutil.rmtree(p, ignore_errors=True)
        os.makedirs(p)

    print(f"[C]onverting v2fh into v2fc and cli_v2fc from {input_v2fh_dir}...")
    for i, forest_path in enumerate(sorted(glob.glob(
            os.path.join(input_v2fh_dir, "**", "*.v2fh"), recursive=True))):
        v2fc_path = os.path.abspath(forest_path).replace(
            input_v2fh_dir, output_v2fc_dir)[:-4] + "v2fc"
        v2fh_to_v2fc(v2fh_path=forest_path, v2fc_path=v2fc_path,
                     verification_bin_path=verification_bin_path)

        cli_v2fc_path = os.path.abspath(forest_path).replace(
            input_v2fh_dir, output_cli_v2fc_dir)[:-4] + "cli_v2fc"
        v2fc_to_cli_v2fc(v2fc_path=v2fc_path, cli_v2fc_path=cli_v2fc_path)


def main():
    print("[G]enerating and verifying all test vectors. This might take a while...")

    print("# V2F code forests")
    import_v2f_codecs()

    print("# Unittest vectors")
    generate_unittest_samples()

    print("# Fuzzing seed vectors")
    generate_fuzzing_entropy_coder_samples()
    generate_fuzzing_entropy_decoder_samples()
    generate_fuzzing_compress_decompress()

    print("# Command line fuzzing vectors")
    generate_command_line_fuzzer_samples()

    print("# Clean fuzzing queues and generate cmin fuzzing vectors")
    clean_fuzzer_queues()
    queue_to_fuzzer_cmin()

    print("# Generate .h/.c sample description files")
    generate_c_sources()

    print("All samples generated successfully")


if __name__ == '__main__':
    main()
